{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07f79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0092db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for log file\n",
    "log_file = r'C:\\Users\\Welcome\\project4\\log\\log_file.txt.txt'\n",
    "transformed_data_path = r\"C:\\Users\\Welcome\\project4\\transformed_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in source path:\n",
      "source1.csv\n",
      "source1.json\n",
      "source1.xml\n",
      "source2.csv\n",
      "source2.json\n",
      "source2.xml\n",
      "source3.csv\n",
      "source3.json\n",
      "source3.xml\n"
     ]
    }
   ],
   "source": [
    "# Set the source path for your files\n",
    "source_path = r'C:\\Users\\Welcome\\project4\\source' \n",
    "files = [f for f in os.listdir(source_path) if os.path.isfile(os.path.join(source_path, f))]\n",
    "print(\"Files in source path:\")\n",
    "\n",
    "for file in files:\n",
    "    print (file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e236b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log messages with timestamps\n",
    "def log(message):\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f'{timestamp} - {message}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8580d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from CSV files\n",
    "def extract_csv(file_path):\n",
    "    try:\n",
    "        log(f\"Extracting data from {file_path}\")\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        log(f\"Failed to extract CSV: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bcc788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from JSON files\n",
    "def extract_json(file_path):\n",
    "    try:\n",
    "        log(f\"Extracting data from {file_path}\")\n",
    "        return pd.read_json(file_path)\n",
    "    except Exception as e:\n",
    "        log(f\"Failed to extract JSON: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c79bce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from XML files\n",
    "def extract_xml(file_path):\n",
    "    try:\n",
    "        log(f\"Extracting data from {file_path}\")\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        data = []\n",
    "        for record in root.findall('record'):\n",
    "            row = {child.tag: child.text for child in record}\n",
    "            data.append(row)\n",
    "        return pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        log(f\"Failed to extract XML: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f9dd476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master function to extract data from all supported file types\n",
    "def extract_data(files):\n",
    "    all_data = pd.DataFrame()\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            df = extract_csv(file)\n",
    "            log(f\"Extracted {len(df)} records from {file}\")  # Log the number of records\n",
    "            all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "        elif file.endswith('.json'):\n",
    "            df = extract_json(file)\n",
    "            log(f\"Extracted {len(df)} records from {file}\")  # Log the number of records\n",
    "            all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "        elif file.endswith('.xml'):\n",
    "            df = extract_xml(file)\n",
    "            log(f\"Extracted {len(df)} records from {file}\")  # Log the number of records\n",
    "            all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4826152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform data (convert heights to meters and weights to kilograms)\n",
    "def transform_data(df):\n",
    "    try:\n",
    "        log(\"Transforming data (converting heights and weights)\")\n",
    "        df['Height'] = pd.to_numeric(df['Height'], errors='coerce')\n",
    "        df['Weight'] = pd.to_numeric(df['Weight'], errors='coerce')\n",
    "        df.dropna(subset=['Height', 'Weight'], inplace=True)\n",
    "        df['Height'] = df['Height'].apply(lambda x: round(float(x) * 0.0254, 2))\n",
    "        df['Weight'] = df['Weight'].apply(lambda x: round(float(x) * 0.453592, 2))\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log(f\"Transformation failed: {e}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "252c19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(df, output_path):\n",
    "    try:\n",
    "        # Ensure the folder exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # Save the CSV\n",
    "        df.to_csv(output_path, index=False)\n",
    "        log(f\"Data successfully saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        log(f\"Failed to load data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "251c172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ETL pipeline function\n",
    "def etl_pipeline():\n",
    "    log(\"ETL process started\")\n",
    "    \n",
    "    # Extraction Phase\n",
    "    log(\"Extraction phase started\")\n",
    "    files = glob.glob(os.path.join(source_path, '*'))  # Using the specified source path\n",
    "    data = extract_data(files)\n",
    "    log(\"Extraction phase completed\")\n",
    "    \n",
    "    # Transformation Phase\n",
    "    log(\"Transformation phase started\")\n",
    "    transformed_data = transform_data(data)\n",
    "    log(\"Transformation phase completed\")\n",
    "    \n",
    "    # Loading Phase\n",
    "    log(\"Loading phase started\")\n",
    "    load_data(transformed_data, transformed_data_path)\n",
    "    log(\"Loading phase completed\")\n",
    "    \n",
    "    log(\"ETL process completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "724b5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ETL pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    etl_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
